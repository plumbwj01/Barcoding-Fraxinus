{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Alignment columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Contig:\n",
    "    def __init__(self, name, seq):\n",
    "        self.name = name\n",
    "        self.seq = seq\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '< \"%s\" %i nucleotides>' % (self.name, len(self.seq))\n",
    "\n",
    "def read_contigs(input_file_path):\n",
    "    contigs = []\n",
    "    current_name = \"\"\n",
    "    seq_collection = []\n",
    "\n",
    "    # Pre-read generates an array of contigs with labels and sequences\n",
    "    with open(input_file_path, 'r') as streamFASTAFile:\n",
    "        for read in streamFASTAFile.read().splitlines():\n",
    "            if read == \"\":\n",
    "                continue\n",
    "            if read[0] == \">\":\n",
    "                # If we have sequence gathered and we run into a second (or more) block\n",
    "                if len(seq_collection) > 0:\n",
    "                    sequence = \"\".join(seq_collection)\n",
    "                    seq_collection = []  # clear\n",
    "                    contigs.append(Contig(current_name, sequence))\n",
    "                current_name = read[1:]  # remove >\n",
    "            else:\n",
    "                # collects the sequence to be stored in the contig, constant time performance don't concat strings!\n",
    "                seq_collection.append(read.upper())\n",
    "\n",
    "    # add the last contig to the list\n",
    "    sequence = \"\".join(seq_collection)\n",
    "    contigs.append(Contig(current_name, sequence))\n",
    "    return contigs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCCCCCCCCTTCCCCACCCAACCCCCCCC 210\n",
      "GGGGGGGGGGGGGGGGGGGGGAGGGGGGG 211\n",
      "CCCCCCCCCCCGCCCCCCCCCCCCCCCCC 212\n",
      "AAATAAAAAAAAAAAAAAAAAAAAAAGGA 216\n",
      "GGGGGGGGGGGAGGGGTTGGGGTGGGGGG 223\n",
      "GGGGGAGGGGGGGGGGGGGGGGGGGGGGG 226\n",
      "TTTTTTTTTTTAAAAAAATTTTTTTTTTT 229\n",
      "TTTTTTTTTTTTTTTTTTT-TTTTTTTTT 232\n",
      "TTTTTTTTTTTTTTTTTTT-TTTTTTTTT 233\n",
      "CCCCCCCCCCCCCCCCCCC-CCCCCCCCC 234\n",
      "TTTTTTTTTTTTTTTTTTT-TTTTTTTTT 235\n",
      "AAAAAAAAAAAAAAAAAAA-AAAAAAAAA 236\n",
      "GGGGGGGGGGGGGGGGGGC-GGGGGGGGG 237\n",
      "TTTTTTTTTTTTTTTTTTT-TTTTTTTTT 238\n",
      "AAAAAAAAAAAAAAAAAAA-AAAAAAAAA 239\n",
      "CCCCCCCCCCCCCCCCCCC-CCCCCCCCC 240\n",
      "CCCCCCCCCCCCCCCACCC-CCCCCCCCC 241\n",
      "AAAAAAAAAAAAAAAAAAA-AAAAAAAAA 242\n",
      "GGGGGGGGGGGGGGGGGGG-GGGGGGGGG 243\n",
      "TTTTTTTTTTTTTTTTTTT-TTTTTTTTT 244\n",
      "AAAAAAAAAAAAAAAAAAA-AAAAAAAAA 245\n",
      "GGGGGGGGGGGGGGGGGGG-GGGGGGGGG 246\n",
      "TTTTTTTTTTTTCTTTTTT-TTTCTTTTT 247\n",
      "GGGGGGGGGGGGGGGGGGG-AGGGGGGGG 248\n",
      "TTTTTTTTTTTTTTTTTTT-TTTTTTTTT 249\n",
      "GGGGGGGGGGGGGGGGGGG-GGGGGGGGG 250\n",
      "GGGGGGGGGGGGGGGGGGG-GGGGGGGGG 251\n",
      "AAAAAAAAAAAAAAAAAAA-AAAAAAAAA 252\n",
      "AAAGAAAAAAAAAAAAAAAAAAAAAAAAA 280\n",
      "CCCCCCCCCCCCCCCCCCTTTACCCCCCC 283\n",
      "TTTTTTTTTTTTTCTTTTAAATTTTTTTT 293\n",
      "AAAAAAAAAAAAAAGGGGAAAAAAAAAAA 311\n",
      "AAAAAAAAAAAAAAAAAAAAAGAAAAAAA 326\n",
      "GGGGGGGGGGGGTTGGGGGGGGGGGGGGG 328\n",
      "TTTTTTTTTATTTTTTTTTTTTTTTTTTT 329\n",
      "AAAAAAAAAAAAAAAAAAAAAAAGAAAAA 342\n",
      "CTTCCCCCCCCCCCCCCCTTTTTTTTTTT 349\n",
      "GGGGGGGGGGGGGGGGGGTTTGGGGGGGG 350\n",
      "GGGGGGGGGGGGGGGGGGGGGGGGGAGGG 372\n",
      "GGGGGGGGGGGGGGGGGGAAAAAAAAAAA 373\n",
      "CTTTTTTTTTTTTTTTTTTTTTTTTTTTT 397\n",
      "CTTCCCCCCCCCCCCCCCCCCCCCCCCCC 442\n",
      "CTTTTTTTTTTTTTTTTTTTTTTTTTTTT 445\n",
      "A---------------------------- 452\n",
      "A---------------------------- 453\n",
      "G---------------------------- 454\n",
      "AAAAAAAAAAAAAAAAAAAGAAAAAAAAA 459\n",
      "ACCCCCCCCCCCCCCCCCCCCCCCCCCCC 464\n",
      "CTTCCCCTCCCCCCCCCCCCCCCCCCCCC 465\n",
      "AAAAAAAAAAAAAAAAAAAAAGAAAAAAA 467\n",
      "TTTTCTTTTTTTTTTTTTTTTTTTTTTTT 475\n",
      "CCCACCCCCCCCCCCCCCCCCCCCCCCCC 485\n",
      "AAAAAAAAAAAAAAAAAAAAAAAGGGAAA 487\n",
      "TCCTTTTTTTTTTTTTTTTTTTTTTTTTT 501\n",
      "TTTTTTCTTTTCTTTTTTTTTTTTTTTTT 514\n",
      "GGGAGGGGGGGGGGGGGGGGGGGGGGGGG 517\n",
      "TCCTTTTTTTTTTTTTTTTTTTTTTTTTT 520\n",
      "TTTCTTTTTTTTTTTTTTTTTGTTTTTTT 523\n",
      "GGTGGGGGGGGGGGGGGGGGGGGGGGGGG 524\n",
      "TTTCTTTTTTTTTTTTTTTTTTTTTTTTT 526\n",
      "TTTTTTTTTTTTTTTTTTTTTTCTTTCCC 537\n",
      "GGGGAGGGGGGGGGGGGGGGGGGGGGGGG 539\n",
      "GTGGGGGGGGGGGGGGGGGGGGGGGGGGG 541\n",
      "GGGGGGGGGGGGGGGGGGAAAGGGGGGGG 545\n",
      "TTTTTTTTTTTTTTCCCCTTTTTTTTTTT 549\n",
      "GGGGGGGGGGGGGGGGGGGGGGGTTGGGG 550\n",
      "GGGGGAGGGGGGGGGGGGGGGGGGGGGGG 552\n",
      "AAGAAAAAAAAAAAAAAAAAAAAAAAAAA 557\n",
      "GGGGGGGAGGGGGGGGGGGGGGGGGGGGG 560\n",
      "TTTTCCCCCCCTTTTTTTTTTCTTTTTTT 577\n",
      "TTTTTTTCTTCTTTTTTTTTTTTTTTTTT 583\n",
      "GGGTGGGGGGGGGGGGGGGGGGGGGGGGG 598\n",
      "AGGAAAAAAAAAAAAAAAGGGGGGGGGGG 599\n",
      "TAAAGAAAAAAAAAAAAAAAAAAACAAAA 602\n",
      "GAAGGGGGGGGGGGGGGGAAAAAAAAAAA 610\n",
      "GGGGGGGGGGGGGGGGGGGGGGGGGGGGA 619\n",
      "AAAAAAAAAAAATAAAAAAAAAAAAAAAA 644\n",
      "AGGAAAAAAAAAAAAAAAGGGGGGGGGGG 646\n",
      "GGGTGGGGGGGGGGGGGGGGGGGGCCGGG 679\n",
      "TGGGGGGGGGGGGGGGGGGGGGGGGGGGG 681\n",
      "TTTTTTTTTTTTTTGTTTTTTTTTTTTTT 686\n",
      "CCCCCCCCCCCCCCCCCCTCCCCCCCCCC 692\n",
      "TTTTATTTTTTTTTTTTTTTTTTTTTTTT 706\n",
      "TTTTTTTTTTTTTTTTTTTTTTTTTTCCC 710\n",
      "GGGGGGGGGGTGGGGGGGGGGGGGGGGGG 719\n",
      "TTTCTTTTTTTTTTTTTTTTTTTTTTTTT 727\n",
      "GGAGGGGGGGGGGGGGGGGGGGGGGGGGG 731\n",
      "GAAGGGGGGGGGGGGGGGGGGGGGGGGGG 733\n",
      "CCCCTTTTTTTTTTTTTTTCCTCCCCCCC 742\n",
      "GAAGGGGGGGGGGGGGGGGGGGGGGGGGG 757\n",
      "GGGGGGGGGGGGAGGGGGGGGGGGGGGGG 764\n",
      "CCCACCCCCCCCCCCCCCCCCCCCCCCCC 775\n",
      "GGGGGGGGGGGGGGGGGGGGGGAAAAAAA 793\n",
      "TTTCCCTTTTTTCCCCCCTTTTTTTTTTT 808\n",
      "GGGGGGGGGGGAGGGGGGGGGGGGGGGGG 832\n",
      "GGGGGGGGGGGGGGGGGGGGGGAAAAAAA 838\n",
      "GGGGGGGGGGGGGTGGGGGGGGGGGGGGG 848\n",
      "-------------G--------------- 849\n",
      "-------------C--------------- 850\n",
      "AAAAAAAAAAAAAAAAAAAAAATAAAAAA 866\n",
      "CTTTTTTTTTTTTTTTTTTTTTTTTTTTT 869\n",
      "AAAAAAAAAAAAAAAGAAAAAAAAAAAAA 870\n",
      "CCCCCCCCCCCCCCCCCCTCCCCCCCCCC 884\n",
      "AAAAGAAAAAAAAAAAAAGGAAAAAAAAA 885\n",
      "GGGGGGGGGGGAGGGGGGGGGGGGGGGGG 888\n",
      "TAATTTTTTTTTTTTTTTTTTTTTTTTTT 919\n",
      "CCCCCCCCCCCCTCCCCCCCCCCCCCCCC 921\n",
      "GGGGGGGGGGGAAAAAAAGGGGGGGGGGG 933\n",
      "GGGAGGGGGGGGAGGGGGGGGGGGGGGGG 939\n",
      "CCCTCTCCCCCCCCCCCCCCCCCCCCCCC 944\n",
      "GGGGGGGGGGGGGAGGGGGGGGGGGGGGG 973\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCTT 981\n",
      "AAAAAAAAAAAAAAAAAAAAAAAACAAAA 982\n",
      "AAAAAAAAAAAAAAAAGGAAAAAAAAAAA 993\n",
      "TTTTTTTTTTTTTTTTTTTTTTCTTTTTT 1008\n",
      "TTTTTTTTTTTTTTTTTTTTTTCCCCCCC 1025\n",
      "TCTCCCCCCCCCCCCCCCCCCCCCCCCCC 1044\n",
      "TTTTTTATATTTTTTTTTTTTTTTTTTTT 1057\n",
      "AGGGGGGGGGGGGGGGGGGGGGGGGGGGG 1069\n",
      "CGGCTCCCCCCCCCCCCCCCCCCCCCCCC 1071\n",
      "GGGGGGGGGGGGGGGGAAGGGGGGGGGGG 1072\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCGCC 1077\n",
      "TTCTTTTTTTTTTTTTTTTTTTTTTTTTT 1081\n",
      "TAAATTTTTTTTTTTTTTAAAAAAAAAAA 1104\n",
      "GGGGGGGGGGGGGGGGGGGGGGTTTTTTT 1125\n",
      "GGGAGGAGAGGGGGGGGGGGGGGGGGGGG 1137\n",
      "TTTTTTTTTTTTCTTTTTTTTTTTTTTTT 1146\n",
      "ATAAAAAAAAAAAAAAAAAAAAAAAAAAA 1149\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAGGA 1152\n",
      "GAGGGGGGGGGGGGGGGGGGGGGGGGGGG 1171\n",
      "TAATTTTTTTTTTTTTTTTTTTTTTTTTT 1181\n",
      "AAAAAAAAATAAAAAAAAAAAAAAAAAAA 1183\n",
      "AAAAAAAAAAAAAAAAAAAAAAGAAAGGG 1197\n",
      "TTTTTCTTTTTTTTTTTTTTTTTTTTTTT 1203\n",
      "AAAAAAAAAAAAAAAAAAAAAGGGGGGGG 1212\n",
      "ATTAAAAAAAAAAAAAAAAAAAAAAAAAA 1235\n",
      "TTTCTTTTTTTTTTTTTTTTTTTTTTTTT 1242\n",
      "GGGGGGGGGGGGGGGGGGTTTGGGGGGGG 1257\n",
      "TCTTTTTTTTTTTTTTTTTTTTTTTTTTT 1272\n",
      "GGGGGGGGGGAGGGGGGGGGGGGGGGGGG 1281\n",
      "GGGGGGGTGGGGGGGGGGGGGGGGGGGGG 1284\n",
      "AGGGGGGGGGGGGGGGGGGGGGGGGGGGG 1304\n",
      "TCCCCCCCCCCCCCCCCCCCCCCCCCCCC 1305\n",
      "AAAAAAAAAAAAAAAAAAAAAGAAAAAAA 1306\n",
      "TGGGGGGGGGGGGGGGGGGGGGGGGGGGG 1309\n",
      "TTTTTTTTTCTTTTTTTTTTTTTTTTTTG 1310\n",
      "CTTCCCTTCCTCTTTTTTTCCCCCCCCCC 1311\n",
      "GGGGGAGGGGCGGGGGGGGGGGAAAAGAA 1312\n",
      "GGGAGGGGGGGGGGGGGGGGGGGGGGGGG 1315\n",
      "TAAAAAAAAAAAAAAAAAAAAAAAAAAAA 1317\n",
      "TAATTTTTTTTTTTTTTTTTTTTTTTTTT 1326\n",
      "AAAAAAAAAGAAAAAAAAAAAAAAAAAAA 1335\n",
      "AAAAAACAAAAGAAAAAAAAAAAAAAAAA 1341\n",
      "AAAAAAAAAATAAAAAAAAAAAAAAAAAA 1344\n",
      "GGGGGGGGGGGGGGGGGGGGGAGGGGGGG 1345\n",
      "GAAAAAAAAAAAAAAAAAAAAAAAAAAAA 1347\n",
      "TGGGGGGGGGGGGGGGGGGGGGGGGGGGG 1348\n",
      "GCGGGGGGGGGGGGGGGGGGGGGGGGGGG 1352\n",
      "TTTCCCCCCCCCCCCCCCCCCCTTTTTTT 1356\n",
      "GGGGGGGGGGGGGGGGGGGAGGGGGGGGG 1363\n",
      "TTTTTTCTTTTTTTTTTTTTTTTTTTTTT 1365\n",
      "TTTTCTCCTTTTTTTTTTTTTTTTTTTTT 1371\n",
      "TTTTTTTTTTGTTTTTTTTTTTTTTTTTT 1381\n",
      "AAAAAAAAAAAATAAAAAAAAAAAAAAAA 1383\n",
      "GGGGGGGGGGGGGGCCCCGGGGGGGGGGG 1384\n",
      "GGGGGGGGGGGGGGGCCCGGGGGGGGGGG 1385\n",
      "CCCCCCCCCCCCCCCGGGCCCCCCCCCCC 1387\n",
      "TTTTTTTTTTTTTTTTTTTCTTTTTTTTT 1392\n",
      "GGGGGGGGGGGGGGGGGGGAGGGGGGGGG 1393\n",
      "GGGGGGGGGGGGGGGGGGAGGGGGGGGGG 1401\n",
      "TTTTTTTTTCTTTTTTTTTTTTTTTTTTT 1413\n",
      "GGGGGGGGGGGGGGGTTTGGGGGGGGGGG 1419\n",
      "TTTTTTTTTTTTTTTCCCTTTTTTTTTTT 1440\n",
      "GGGGGGGGGGGAGGGGGGGGGGGGGGGGG 1452\n",
      "TTTTGGGGGGGGGGGGGGTTTTTTTTTTT 1466\n",
      "TTTTTTTTTTTCTTTTTTTTTTTTTTTTT 1479\n",
      "TGGGGGGGGGGGAGGGGGGGGGGGGGAGG 1487\n",
      "CCCTCCCCCCCCCCCCCCCCCCCCCCCCC 1497\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "species = read_contigs('9927_alignment.fasta')\n",
    "for s in species:\n",
    "    s.name = s.name[:6]\n",
    "informative_columns = {}\n",
    "consensus_sequence = []\n",
    "for col in range(len(species[0].seq)):\n",
    "    letters = []\n",
    "    for entry in species:\n",
    "        letters.append(entry.seq[col])\n",
    "    column_seq = ''.join(letters)\n",
    "    consensusing = Counter(column_seq)\n",
    "    consensus_sequence.append(consensusing.most_common()[0][0])\n",
    "    if column_seq != letters[0] * len(species) and col > 200 and col < 1500:\n",
    "        informative_columns[col] = column_seq\n",
    "        print(column_seq, col+1)\n",
    "species.append(Contig('Consen', ''.join(consensus_sequence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate a fasta with informative columns\n",
    "* Majority vote consensus sequence, but it includes gaps\n",
    "* transpose?\n",
    "* CSV file write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('9927_informative_positions.csv', 'w') as csv_out:\n",
    "    csv_out.write('Positions,' + ','.join([str(x+1) for x in sorted(informative_columns.keys())]))\n",
    "    csv_out.write('\\n')\n",
    "    for entry in species:\n",
    "        csv_out.write(entry.name[:6] + \",\")\n",
    "        for col in range(len(species[0].seq)):\n",
    "            if col in informative_columns:\n",
    "                csv_out.write(entry.seq[col] + \",\")\n",
    "        csv_out.write('\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair wise table\n",
    "How well can you differentiate between every species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Consen', 'FRAEX3')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = len(species[0].seq)\n",
    "similarity_scores = {}\n",
    "for target in species:\n",
    "    for query in species:\n",
    "        if target != query:\n",
    "            name = (target.name, query.name)\n",
    "            score = sum([target.seq[i] != query.seq[i] for i in range(250,1500)])\n",
    "            similarity_scores[name] = score\n",
    "min(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('9927_differentiability.csv', 'w') as csv_out:\n",
    "    csv_out.write(',' + ','.join([s.name for s in species]))\n",
    "    for target in species: # rows\n",
    "        csv_out.write(target.name +',')\n",
    "        for query in species: # cells\n",
    "            if target != query:\n",
    "                name = (target.name, query.name)\n",
    "                csv_out.write(str(similarity_scores[name]) + ',')\n",
    "            else:\n",
    "                csv_out.write(',')\n",
    "        csv_out.write('\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(similarity_scores.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRAX09,FRAX10\n",
      "FRAX15,FRAX16\n",
      "FRAX15,FRAX01\n",
      "FRAX16,FRAX15\n",
      "FRAX01,FRAX16\n",
      "FRAX16,FRAX01\n",
      "FRAX01,FRAX15\n",
      "FRAX10,FRAX09\n"
     ]
    }
   ],
   "source": [
    "for k,v in similarity_scores.items():\n",
    "    if v < 4:\n",
    "        print(','.join(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Iterate over all the sequences at the same time\n",
    "* for each position, how many species can you differentiate\n",
    "* keep of list of species "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Other Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_command = \"java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats \"\n",
    "data_directory = './Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG100_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n",
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG133_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n",
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG149_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n",
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG237_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n",
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG267_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n",
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG293_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n",
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG436_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n",
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG439_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n",
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG495_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n",
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG555_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n",
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG571_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n",
      "java -cp CONTEXT-.jar uk.ac.qmul.sbcs.evolution.convergence.runners.BasicAlignmentStats ./Data\\OG70_full_length_guidance_results_full_length_MUSCLE.MSA.MUSCLE.Without_low_SP_Col.With_Names.fasta\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "for filename in glob(data_directory + '*'):\n",
    "    print(base_command + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Processing FinchTV FASTA outputs into and alignment\n",
    "* Example output FASTA file with all the N's and ugliness\n",
    "* Load up consensus MSA\n",
    "* Initial cleanup (lenient)\n",
    "    * First 50bp are low accuracy => trim them\n",
    "* Force Alignment onto MSA\n",
    "    * Do not allow Consensus to have indels introduced, so that we can continue to use the same coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes from Jan Kim\n",
    "* Heterozygosity inside a single PCR product is a problem because any bias in amplification will exponentially become dominant.\n",
    "    * PCR as few steps as possible\n",
    "    * Don't expect perfect 50/50 spilts in the ABI trace\n",
    "* Geneous (or manual) base caller with ambiguity codes for all significant peaks, not just the tallest\n",
    "* Do much of this manually, there are only 40 specimens\n",
    "* Possibly use pairwise alignments that are ambiguity aware to check for best species match\n",
    "* You could also still use a frozen Multiple Sequence Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
